---
title: "iteration_and_listcols"
author: "Paula Wu"
date: "11/9/2021"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
library(tidyverse)
set.seed(1)
```


## lists
```{r}
l = list(
  vec_numeric = 5:8,
  vec_logical = c(TRUE, FALSE),
  summary = summary(rnorm(1000, mean = 5, sd = 3))
)

l[[3]]
l[["summary"]]
l$summary  # you can use $ here
```

## lists of normals
```{r}
list_norms = 
  list(
    a = rnorm(50, mean = 2, sd = 1),
    b = rnorm(50, mean = 5, sd = 3),
    c = rnorm(50, mean = 20, sd = 1.2),
    d = rnorm(50, mean = -12, sd = 1),
    e = rnorm(50, mean = 0, sd = 1)
  )
```

```{r}
mean_and_sd = function(x) {
  
  if (!is.numeric(x)) {
    stop("Argument x should be numeric")
  } else if (length(x) == 1) {
    stop("Cannot be computed for length 1 vectors")
  }
  
  mean_x = mean(x)
  sd_x = sd(x)

  tibble(
    mean = mean_x, 
    sd = sd_x
  )
}
```

```{r}
mean_and_sd(list_norms[[1]]) # you can do this for 5 times, or write a for-loop
```

## create an output list and for loop
```{r}
# merge?
output = vector("list", length = 5)
for (i in 1:5){
  output[[i]] = mean_and_sd(list_norms[[i]])
}
output
```
Let's us map instead
```{r}
output = map(list_norms, mean_and_sd)
output = map(list_norms, summary)
output = map_dbl(list_norms, median)  # collapse down into a simpler version
```

## List columns
```{r}
listcol_df = 
  tibble(
    name = c("a","b","c","d"),
    norms = list_norms[1:4]
  )
listcol_df %>% 
  filter(name == "a")
listcol_df %>% pull(name)
listcol_df %>% pull(norms)

mean_and_sd(listcol_df$norms[[1]])
map(listcol_df$norms, mean_and_sd)

listcol_df %>% 
  mutate(summaries = map(listcol_df$norms, mean_and_sd)) %>% 
  pull(summaries)
```
## Nested data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728", "USC00519397", "USS0023B17S"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(
      id, 
      USW00094728 = "CentralPark_NY", 
      USC00519397 = "Waikiki_HA",
      USS0023B17S = "Waterhole_WA"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Nest data within location
```{r}
weather_nest = 
  nest(weather_df, data = date:tmin)  # nest all data (date to tmin) into the "data" column

weather_nest
weather_nest %>% 
  filter(name == "CentralPark_NY") %>% 
  pull(data)
```

linear regression
```{r}
weather_lm = function(df) {
  lm(tmax ~ tmin, data = df)
}
weather_lm(weather_nest$data[[1]])  # weather_lm on central park
```
```{r}
map(weather_nest$data, weather_lm)
weather_nest %>% 
  mutate(lm_results = map(data, weather_lm))
```
```{r}
unnest(weather_nest,data) # unnest the data
```


## Revisiting Napolean
```{r}
library(rvest)
```

```{r}
read_page_reviews = function(url) {
  
  html = read_html(url)
  
  title = 
    html %>%
    html_nodes("#cm_cr-review_list .review-title") %>%
    html_text()
  
  stars = 
    html %>%
    html_nodes("#cm_cr-review_list .review-rating") %>%
    html_text() %>%
    str_extract("\\d") %>%
    as.numeric()
  
  text = 
    html %>%
    html_nodes(".review-data:nth-child(5)") %>%
    html_text()
  
  tibble(title, stars, text)
}
```
```{r}
url_base = "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber="
vec_urls = str_c(url_base, 1:5)
```
```{r}
map(vec_urls, read_page_reviews)
nepolean_df = 
  tibble(
    urls = vec_urls
  )
nepolean_df %>% 
  mutate(reviews = map(urls, read_page_reviews)) %>% 
  select(reviews) %>% 
  unnest()
```
```{r}
output = vector("list", 5)

for (i in 1:5) {
  output[[i]] = read_page_reviews(vec_urls[[i]])
}
```


